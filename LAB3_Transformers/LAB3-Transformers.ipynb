{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08e91cdb-4693-4632-b7aa-f37eec027131",
   "metadata": {},
   "source": [
    "## Working with Transformers in the HuggingFace Ecosystem\n",
    "\n",
    "In this laboratory exercise we will learn how to work with the HuggingFace ecosystem to adapt models to new tasks. As you will see, much of what is required is *investigation* into the inner-workings of the HuggingFace abstractions. With a little work, a little trial-and-error, it is fairly easy to get a working adaptation pipeline up and running."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e556105-269f-43e3-8933-227269afb9ea",
   "metadata": {},
   "source": [
    "### Exercise 1: Sentiment Analysis (warm up)\n",
    "\n",
    "In this first exercise we will start from a pre-trained BERT transformer and build up a model able to perform text sentiment analysis. Transformers are complex beasts, so we will build up our pipeline in several explorative and incremental steps.\n",
    "\n",
    "#### Exercise 1.1: Dataset Splits and Pre-trained model\n",
    "There are a many sentiment analysis datasets, but we will use one of the smallest ones available: the [Cornell Rotten Tomatoes movie review dataset](cornell-movie-review-data/rotten_tomatoes), which consists of 5,331 positive and 5,331 negative processed sentences from the Rotten Tomatoes movie reviews.\n",
    "\n",
    "**Your first task**: Load the dataset and figure out what splits are available and how to get them. Spend some time exploring the dataset to see how it is organized. Note that we will be using the [HuggingFace Datasets](https://huggingface.co/docs/datasets/en/index) library for downloading, accessing, splitting, and batching data for training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15819af4-e850-412b-ab67-61b9b98e3a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, get_dataset_split_names\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"rotten_tomatoes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "137db36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 8530\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 1066\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61d73b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .', 'label': 1}\n",
      "{'text': 'the gorgeously elaborate continuation of \" the lord of the rings \" trilogy is so huge that a column of words cannot adequately describe co-writer/director peter jackson\\'s expanded vision of j . r . r . tolkien\\'s middle-earth .', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "# Guarda le prime frasi e le etichette\n",
    "print(dataset[\"train\"][0])\n",
    "print(dataset[\"train\"][1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27f50a0-0af4-4bdd-9a60-bab26f126c14",
   "metadata": {},
   "source": [
    "#### Exercise 1.2: A Pre-trained BERT and Tokenizer\n",
    "\n",
    "The model we will use is a *very* small BERT transformer called [Distilbert](https://huggingface.co/distilbert/distilbert-base-uncased) this model was trained (using self-supervised learning) on the same corpus as BERT but using the full BERT base model as a *teacher*.\n",
    "\n",
    "**Your next task**: Load the Distilbert model and corresponding tokenizer. Use the tokenizer on a few samples from the dataset and pass the tokens through the model to see what outputs are provided. I suggest you use the [`AutoModel`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html) class (and the `from_pretrained()` method) to load the model and `AutoTokenizer` to load the tokenizer)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3eefc651-8551-44c2-8340-37d64660fc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/transformers/lib/python3.10/site-packages/torchvision/io/image.py:14: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/envs/transformers/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Library not loaded: @rpath/libjpeg.9.dylib\n",
      "  Referenced from: <0B7EB158-53DC-3403-8A49-22178CAB4612> /opt/anaconda3/envs/transformers/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Reason: tried: '/opt/anaconda3/envs/transformers/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/transformers/lib/python3.10/site-packages/torchvision/../../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/transformers/lib/python3.10/lib-dynload/../../libjpeg.9.dylib' (no such file), '/opt/anaconda3/envs/transformers/bin/../lib/libjpeg.9.dylib' (no such file)'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "# Carichiamo il tokenizer e il modello distilBERT pre-addestrati\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModel.from_pretrained(\"distilbert-base-uncased\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "479143b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frase: the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .\n",
      "Token IDs: tensor([[  101,  1996,  2600,  2003, 16036,  2000,  2022,  1996,  7398,  2301,\n",
      "          1005,  1055,  2047,  1000, 16608,  1000,  1998,  2008,  2002,  1005,\n",
      "          1055,  2183,  2000,  2191,  1037, 17624,  2130,  3618,  2084,  7779,\n",
      "         29058,  8625, 13327,  1010,  3744,  1011, 18856, 19513,  3158,  5477,\n",
      "          4168,  2030,  7112, 16562,  2140,  1012,   102]])\n"
     ]
    }
   ],
   "source": [
    "# Prendiamo una frase di esempio dal dataset\n",
    "sample_text = dataset[\"train\"][0][\"text\"]\n",
    "print(\"Frase:\", sample_text)\n",
    "\n",
    "# Tokenizzazione con padding e truncation automatici\n",
    "inputs = tokenizer(sample_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "print(\"Token IDs:\", inputs[\"input_ids\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5872cc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 47, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Output di DistilBERT\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# Il modello ritorna un dizionario con almeno \"last_hidden_state\"\n",
    "last_hidden_state = outputs.last_hidden_state\n",
    "print(\"Output shape:\", last_hidden_state.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0f6fd4-b80b-466d-b4ff-9aac0492c062",
   "metadata": {},
   "source": [
    "#### Exercise 1.3: A Stable Baseline\n",
    "\n",
    "In this exercise I want you to:\n",
    "1. Use Distilbert as a *feature extractor* to extract representations of the text strings from the dataset splits;\n",
    "2. Train a classifier (your choice, by an SVM from Scikit-learn is an easy choice).\n",
    "3. Evaluate performance on the validation and test splits.\n",
    "\n",
    "These results are our *stable baseline* -- the **starting** point on which we will (hopefully) improve in the next exercise.\n",
    "\n",
    "**Hint**: There are a number of ways to implement the feature extractor, but probably the best is to use a [feature extraction `pipeline`](https://huggingface.co/tasks/feature-extraction). You will need to interpret the output of the pipeline and extract only the `[CLS]` token from the *last* transformer layer. *How can you figure out which output that is?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ebb961ab-aa24-4d5c-86a1-c9b4237b40fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Crea un pipeline per feature extraction\n",
    "extractor = pipeline(\"feature-extraction\", model=\"distilbert-base-uncased\", tokenizer=\"distilbert-base-uncased\", device=-1)  # usa CPU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17257a51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 47 768\n"
     ]
    }
   ],
   "source": [
    "text = dataset[\"train\"][0][\"text\"]\n",
    "features = extractor(text)\n",
    "print(len(features), len(features[0]), len(features[0][0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41ddbf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_vector = features[0][0]  # Embedding [CLS] da 768 valori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fecd54bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cls_features(dataset_split):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for example in dataset_split:\n",
    "        text = example[\"text\"]\n",
    "        label = example[\"label\"]\n",
    "        output = extractor(text, truncation=True, padding=True)\n",
    "        cls_vector = output[0][0]  # [CLS] embedding\n",
    "        features.append(cls_vector)\n",
    "        labels.append(label)\n",
    "    return features, labels\n",
    "\n",
    "X_train, y_train = extract_cls_features(dataset[\"train\"])[:1000]\n",
    "X_val, y_val = extract_cls_features(dataset[\"validation\"])\n",
    "X_test, y_test = extract_cls_features(dataset[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec826ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8189493433395872\n",
      "Test Accuracy: 0.8067542213883677\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "clf = SVC(kernel=\"linear\")\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "val_preds = clf.predict(X_val)\n",
    "test_preds = clf.predict(X_test)\n",
    "\n",
    "print(\"Validation Accuracy:\", accuracy_score(y_val, val_preds))\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, test_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc18404",
   "metadata": {},
   "source": [
    "### Risultati:\n",
    "\n",
    "- **Accuratezza sul validation set**: circa 81,9%  \n",
    "- **Accuratezza sul test set**: circa 80,7%\n",
    "\n",
    "---\n",
    "\n",
    "### Punti chiave:\n",
    "\n",
    "- Anche **senza effettuare il fine-tuning**, l’utilizzo degli embedding pre-addestrati di un Transformer fornisce una **baseline molto solida**.\n",
    "- Le performance ottenute **superano nettamente** approcci classici di classificazione testuale (es. Bag-of-Words + Regressione Logistica).\n",
    "- Questo approccio rappresenta un’alternativa **leggera e veloce** rispetto al fine-tuning completo, ideale per la prototipazione o per sistemi con risorse computazionali limitate.\n",
    "- Questi risultati costituiscono un **punto di riferimento** con cui confrontare eventuali miglioramenti ottenuti tramite fine-tuning o con architetture diverse.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37141d1b-935b-425c-804c-b9b487853791",
   "metadata": {},
   "source": [
    "-----\n",
    "### Exercise 2: Fine-tuning Distilbert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a53f64-0238-42f2-bc20-86e51c77d2e5",
   "metadata": {},
   "source": [
    "In this exercise we will fine-tune the Distilbert model to (hopefully) improve sentiment analysis performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3392b1ed-597b-4a92-90fc-10eb11eac515",
   "metadata": {},
   "source": [
    "#### Exercise 2.1: Token Preprocessing\n",
    "\n",
    "The first thing we need to do is *tokenize* our dataset splits. Our current datasets return a dictionary with *strings*, but we want *input token ids* (i.e. the output of the tokenizer). This is easy enough to do my hand, but the HugginFace `Dataset` class provides convenient, efficient, and *lazy* methods. See the documentation for [`Dataset.map`](https://huggingface.co/docs/datasets/v3.5.0/en/package_reference/main_classes#datasets.Dataset.map).\n",
    "\n",
    "**Tip**: Verify that your new datasets are returning for every element: `text`, `label`, `intput_ids`, and `attention_mask`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e6e2a95-5b08-4f81-b824-59a0fb3404e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        padding=\"max_length\", #per uniformare la lunghezza \n",
    "        truncation=True,\n",
    "        max_length=128  #lunghezza massima del testo\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83579dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8e51db9a5c4eb4ab7be16bebc88049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8530 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Tokenizza ogni elemento del dataset in modo efficiente e batchato\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d2bee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text', 'label', 'input_ids', 'attention_mask']\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_datasets[\"train\"].column_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "923d813b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'the rock is destined to be the 21st century\\'s new \" conan \" and that he\\'s going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .',\n",
       " 'label': 1,\n",
       " 'input_ids': [101,\n",
       "  1996,\n",
       "  2600,\n",
       "  2003,\n",
       "  16036,\n",
       "  2000,\n",
       "  2022,\n",
       "  1996,\n",
       "  7398,\n",
       "  2301,\n",
       "  1005,\n",
       "  1055,\n",
       "  2047,\n",
       "  1000,\n",
       "  16608,\n",
       "  1000,\n",
       "  1998,\n",
       "  2008,\n",
       "  2002,\n",
       "  1005,\n",
       "  1055,\n",
       "  2183,\n",
       "  2000,\n",
       "  2191,\n",
       "  1037,\n",
       "  17624,\n",
       "  2130,\n",
       "  3618,\n",
       "  2084,\n",
       "  7779,\n",
       "  29058,\n",
       "  8625,\n",
       "  13327,\n",
       "  1010,\n",
       "  3744,\n",
       "  1011,\n",
       "  18856,\n",
       "  19513,\n",
       "  3158,\n",
       "  5477,\n",
       "  4168,\n",
       "  2030,\n",
       "  7112,\n",
       "  16562,\n",
       "  2140,\n",
       "  1012,\n",
       "  102,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets[\"train\"][0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a80de2-83c9-4c12-af4e-34babe23ffd1",
   "metadata": {},
   "source": [
    "#### Exercise 2.2: Setting up the Model to be Fine-tuned\n",
    "\n",
    "In this exercise we need to prepare the base Distilbert model for fine-tuning for a *sequence classification task*. This means, at the very least, appending a new, randomly-initialized classification head connected to the `[CLS]` token of the last transformer layer. Luckily, HuggingFace already provides an `AutoModel` for just this type of instantiation: [`AutoModelForSequenceClassification`](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelforsequenceclassification). You will want you instantiate one of these for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6327d73-3b71-478a-9932-bb062a650c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# 2 classi: positivo e negativo\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2  # importante per classificazione binaria\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efbc1a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x TransformerBlock(\n",
       "          (attention): DistilBertSdpaAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109f7bd-955f-4fc4-bc3e-75bd99a17adf",
   "metadata": {},
   "source": [
    "#### Exercise 2.3: Fine-tuning Distilbert\n",
    "\n",
    "Finally. In this exercise you should use a HuggingFace [`Trainer`](https://huggingface.co/docs/transformers/main/en/trainer) to fine-tune your model on the Rotten Tomatoes training split. Setting up the trainer will involve (at least):\n",
    "\n",
    "\n",
    "1. Instantiating a [`DataCollatorWithPadding`](https://huggingface.co/docs/transformers/en/main_classes/data_collator) object which is what *actually* does your batch construction (by padding all sequences to the same length).\n",
    "2. Writing an *evaluation function* that will measure the classification accuracy. This function takes a single argument which is a tuple containing `(logits, labels)` which you should use to compute classification accuracy (and maybe other metrics like F1 score, precision, recall) and return a `dict` with these metrics.  \n",
    "3. Instantiating a [`TrainingArguments`](https://huggingface.co/docs/transformers/v4.51.1/en/main_classes/trainer#transformers.TrainingArguments) object using some reasonable defaults.\n",
    "4. Instantiating a `Trainer` object using your train and validation splits, you data collator, and function to compute performance metrics.\n",
    "5. Calling `trainer.train()`, waiting, waiting some more, and then calling `trainer.evaluate()` to see how it did.\n",
    "\n",
    "**Tip**: When prototyping this laboratory I discovered the HuggingFace [Evaluate library](https://huggingface.co/docs/evaluate/en/index) which provides evaluation metrics. However I found it to have insufferable layers of abstraction and getting actual metrics computed. I suggest just using the Scikit-learn metrics..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab17178d-5028-47e3-af97-953e8de5aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f71edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    return {\"accuracy\": acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f80d855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132e6aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])  # solo input_ids etc.\n",
    "tokenized_datasets.set_format(\"torch\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9685455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/nmg8_p0n0jl67kvqh6fp_6f80000gn/T/ipykernel_9655/596160775.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "213fa4c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1602' max='1602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1602/1602 13:58, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.426600</td>\n",
       "      <td>0.389991</td>\n",
       "      <td>0.827392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.252500</td>\n",
       "      <td>0.390330</td>\n",
       "      <td>0.854597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162600</td>\n",
       "      <td>0.488452</td>\n",
       "      <td>0.857411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1602, training_loss=0.271679728813981, metrics={'train_runtime': 843.3063, 'train_samples_per_second': 30.345, 'train_steps_per_second': 1.9, 'total_flos': 847460182901760.0, 'train_loss': 0.271679728813981, 'epoch': 3.0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1db9bcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='134' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5327609181404114,\n",
       " 'eval_accuracy': 0.8424015009380863,\n",
       " 'eval_runtime': 8.7536,\n",
       " 'eval_samples_per_second': 121.778,\n",
       " 'eval_steps_per_second': 7.654,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"validation\"])\n",
    "trainer.evaluate(tokenized_datasets[\"test\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abfdccbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('distilbert-finetuned-rotten/tokenizer_config.json',\n",
       " 'distilbert-finetuned-rotten/special_tokens_map.json',\n",
       " 'distilbert-finetuned-rotten/vocab.txt',\n",
       " 'distilbert-finetuned-rotten/added_tokens.json',\n",
       " 'distilbert-finetuned-rotten/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"distilbert-finetuned-rotten\")\n",
    "tokenizer.save_pretrained(\"distilbert-finetuned-rotten\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47599ff6",
   "metadata": {},
   "source": [
    "### **Risultati ottenuti:**\n",
    "\n",
    "| Epoca | Loss Training | Loss Validation | Accuratezza Validation |\n",
    "|-------|----------------|------------------|--------------------------|\n",
    "| 1     | 0.4266         | 0.3899           | 82.74%                   |\n",
    "| 2     | 0.2525         | 0.3903           | 85.46%                   |\n",
    "| 3     | 0.1626         | 0.4884           | 85.74%                   |\n",
    "\n",
    "- **Accuratezza finale sul test set**: **84.24%**\n",
    "- **Loss sul test set**: **0.5327**\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusioni**\n",
    "\n",
    "- Il modello fine-tuned ha **superato la baseline** ottenuta con l’SVM e le feature statiche di BERT (~80%).\n",
    "- Il **fine-tuning di DistilBERT** ha permesso al modello di adattare le sue rappresentazioni linguistiche al compito specifico di sentiment analysis, migliorando sensibilmente le performance.\n",
    "- Il lieve aumento della loss di validazione durante la terza epoca potrebbe indicare l’inizio di un **overfitting**; quindi **2 epoche** potrebbero rappresentare un miglior compromesso per la generalizzazione.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8376de-8554-4a13-aac3-59257f3eb3fd",
   "metadata": {},
   "source": [
    "-----\n",
    "### Exercise 3: Choose at Least One\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b55cf4d-e64b-47fc-b8d5-37288b72d90d",
   "metadata": {},
   "source": [
    "#### Exercise 3.1: Efficient Fine-tuning for Sentiment Analysis (easy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f183856-1111-4fe9-81f1-691fe7c1b706",
   "metadata": {},
   "source": [
    "In Exercise 2 we fine-tuned the *entire* Distilbert model on Rotten Tomatoes. This is expensive, even for a small model. Find an *efficient* way to fine-tune Distilbert on the Rotten Tomatoes dataset (or some other dataset).\n",
    "\n",
    "**Hint**: You could check out the [HuggingFace PEFT library](https://huggingface.co/docs/peft/en/index) for some state-of-the-art approaches that should \"just work\". How else might you go about making fine-tuning more efficient without having to change your training pipeline from above?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ea6bca5-9b36-424e-898c-52c0777eae5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6f999a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n"
     ]
    }
   ],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8, #dimensione del LoRA\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q_lin\", \"v_lin\"]  # Moduli di attenzione in DistilBERT\n",
    ")\n",
    "\n",
    "# Integra LoRA nel modello\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9aa4c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding, TrainingArguments, Trainer\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,  # puoi usare un LR più alto con LoRA\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./lora-logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34e4a245",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cy/nmg8_p0n0jl67kvqh6fp_6f80000gn/T/ipykernel_10261/1545714826.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "No label_names provided for model class `PeftModelForSequenceClassification`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1602' max='1602' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1602/1602 09:04, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.417500</td>\n",
       "      <td>0.407209</td>\n",
       "      <td>0.825516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.366561</td>\n",
       "      <td>0.835835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.364019</td>\n",
       "      <td>0.839587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1602, training_loss=0.34584622019983263, metrics={'train_runtime': 545.7164, 'train_samples_per_second': 46.892, 'train_steps_per_second': 2.936, 'total_flos': 861995355310080.0, 'train_loss': 0.34584622019983263, 'epoch': 3.0})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "793f9745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:12]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.40298429131507874,\n",
       " 'eval_accuracy': 0.8311444652908068,\n",
       " 'eval_runtime': 12.6264,\n",
       " 'eval_samples_per_second': 84.426,\n",
       " 'eval_steps_per_second': 5.306,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_datasets[\"test\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c27939",
   "metadata": {},
   "source": [
    "### Risultati:\n",
    "\n",
    "| Epoca | Loss Training | Loss Validation | Accuratezza Validation |\n",
    "|-------|----------------|------------------|--------------------------|\n",
    "| 1     | 0.4175         | 0.4072           | 82.55%                   |\n",
    "| 2     | 0.3415         | 0.3666           | 83.58%                   |\n",
    "| 3     | 0.2918         | 0.3640           | 83.96%                   |\n",
    "\n",
    "- **Accuratezza finale sul test set**: **83.11%**\n",
    "- **Loss finale sul test set**: **0.4030**\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusioni:\n",
    "\n",
    "- LoRA ha permesso un **fine-tuning efficiente** di DistilBERT, ottenendo prestazioni quasi identiche al fine-tuning completo (≈84% di accuratezza).\n",
    "- Il tempo di addestramento e l’uso di memoria sono stati **significativamente ridotti**.\n",
    "- Questo rende LoRA un approccio potente e pratico per adattare modelli linguistici di grandi dimensioni a nuovi task, specialmente in contesti con risorse limitate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48296bb0",
   "metadata": {},
   "source": [
    "### Confronto delle performance: SVM vs Full Fine-Tuning vs LoRA\n",
    "\n",
    "| Approccio              | Tipo di Addestramento             | Accuratezza (Test) | Note |\n",
    "|------------------------|-----------------------------------|---------------------|------|\n",
    "| **SVM (Esercizio 1.3)** | DistilBERT congelato + SVM       | ~80.7%              | Veloce, leggero, ma meno flessibile |\n",
    "| **Fine-Tuning completo** | Tutti i pesi di DistilBERT aggiornati | ~84.2%        | Miglior accuratezza, ma richiede molte risorse |\n",
    "| **LoRA (PEFT)**        | Solo gli adapter LoRA aggiornati  | ~83.1%              | Quasi pari al fine-tuning completo, ma molto più efficiente |\n",
    "\n",
    "---\n",
    "\n",
    "### Riassumendo...\n",
    "\n",
    "- La **baseline con SVM** è un ottimo punto di partenza con risorse minime, ma non permette al modello di adattarsi a fondo al task.\n",
    "- Il **fine-tuning completo** offre le prestazioni migliori, ma a un costo computazionale più elevato.\n",
    "- **LoRA** rappresenta un **giusto compromesso** tra performance ed efficienza: si avvicina molto all’accuratezza del fine-tuning completo aggiornando solo una **piccolissima parte dei parametri**.\n",
    "\n",
    "Questo dimostra come i metodi di **fine-tuning a basso costo parametrico** come LoRA siano ideali per applicazioni reali, soprattutto quando si lavora con risorse computazionali limitate o si ha bisogno di adattare velocemente modelli a nuovi compiti.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eeca737-ee00-4d98-a3ae-f4d6eb3d264f",
   "metadata": {},
   "source": [
    "#### Exercise 3.2: Fine-tuning a CLIP Model (harder)\n",
    "\n",
    "Use a (small) CLIP model like [`openai/clip-vit-base-patch16`](https://huggingface.co/openai/clip-vit-base-patch16) and evaluate its zero-shot performance on a small image classification dataset like ImageNette or TinyImageNet. Fine-tune (using a parameter-efficient method!) the CLIP model to see how much improvement you can squeeze out of it.\n",
    "\n",
    "**Note**: There are several ways to adapt the CLIP model; you could fine-tune the image encoder, the text encoder, or both. Or, you could experiment with prompt learning.\n",
    "\n",
    "**Tip**: CLIP probably already works very well on ImageNet and ImageNet-like images. For extra fun, look for an image classification dataset with different image types (e.g. *sketches*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00b59ec2-4fe6-44c6-ab0b-0069f486bbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe42ed48-444d-47d4-bd8b-839a99e7996a",
   "metadata": {},
   "source": [
    "#### Exercise 3.3: Choose your Own Adventure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f9129-ef2e-45f7-9e8f-baa697ccd91e",
   "metadata": {},
   "source": [
    "There are a *ton* of interesting and fun models on the HuggingFace hub. Pick one that does something interesting and adapt it in some way to a new task. Or, combine two or more models into something more interesting or fun. The sky's the limit.\n",
    "\n",
    "**Note**: Reach out to me by email or on the Discord if you are unsure about anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c150bd36-6535-4724-a06d-a61632d3132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
